%PSOGSA source code v3.0, Generated by SeyedAli Mirjalili, 2011. 
%Adopted from: S. Mirjalili, S.Z. Mohd Hashim, A New Hybrid PSOGSA 
%Algorithm for Function Optimization, in IEEE International Conference 
%on Computer and Information Application?ICCIA 2010), China, 2010, pp.374-377.

clear all;
clc;
% 加载数据,使用txt.或xls都可，注意 data.xls在上一层目录，可以更换成你的新数据
% data=importdata('data.txt');
data  = xlsread('../data.xls'); % .. 表示上一层目录
[data_r, data_c] = size(data);
test_num = 14;
features = data(:,1 : data_c - 1);
%最大最小归一化，则矩阵每一行为一个维度，每一列是一个样本。
% features = mapminmax(features);
%标准归一化，每一行为一个样本，每一列是一个维度。
features = zscore(features);
%标签列
labels  = data(:,data_c);
%训练集、测试集分割出来
testing_set = features(data_r-test_num+1:data_r,:);
y_testing_set = labels(data_r-test_num+1:data_r,: );

 training_set = features(1:data_r-test_num, :);
 y_training_set = labels(1:data_r-test_num, :);
% 种群规模
N =50;                        % Size of the swarm " no of objects "
%最大迭代次数
Max_Iteration  = 100;              % Maximum number of "iterations"
% 功能ID，24对应是我自定义的SVR的适应度函数。返回的是mse
Benchmark_Function_ID=24; %Benchmark function ID
%调用PSOGSA函数，返回计算后的
[gBestScore,gBest,GlobalBestCost] = PSOGSA(Benchmark_Function_ID, N, Max_Iteration,training_set,y_training_set);

%选择经过PSOGSA寻优化后的C，gama
C = gBest(1);
gama= gBest(2);
fprintf('The best C is %8.5f, the best gamma is %8.5f via PSOGSA \n',C,gama);
% 用最佳参数训练模型，并测试效果
 model = fitrsvm(training_set,y_training_set,'BoxConstraint',C, 'KernelScale',gama,'KernelFunction','rbf');
 y_test_predict = predict(model,testing_set);
 %计算测试集MSE
test_error = y_test_predict - y_testing_set;
YReal = y_testing_set;
YPred = y_test_predict;
% MSE
mse = mse(test_error);

%MAE
mae = mean(abs(YReal - YPred));
%决定系数
r2 = 1 - (sum((YPred - YReal).^2) / sum((YReal - mean(YReal)).^2));
%相关系数
[R,P5] = corr(YReal,YPred);

fprintf('The mse is %8.5f,  mae is %8.5f, R  is %8.5f\n',mse,mae,R);


 %使用SVR进行训练
%  Mdl = fitrsvm(training_set,y_training_set,'KernelFunction','gaussian','KernelScale','auto','Standardize',true);
%  MdlGau = fitrsvm(training_set,y_training_set,'BoxConstraint',1, 'KernelScale',1,'KFold',5,'KernelFunction','gaussian');
%  MdlGau = fitrsvm(training_set,y_training_set,'KFold',5,'KernelFunction','gaussian');
%  mseGau = kfoldLoss(MdlGau);
%  model = fitrsvm(training_set,y_training_set,'KernelFunction','gaussian');
%  y_train_predict = predict(model,training_set);
%  plot(y_training_set,y_train_predict)
 % 使用fitrsvm自动优化超参数。通过使用自动超参数优化，找到使交叉验证损失减少五倍的超参数。
% rng default
% Mdl = fitrsvm(X,Y,'OptimizeHyperparameters','auto',...
%     'HyperparameterOptimizationOptions',struct('AcquisitionFunctionName',...
%     'expected-improvement-plus'))
% 预测
% fit = predict(Mdl,X)

% plot(Y,fit,'.')
 %加载PSOGSA
 
% semilogy(GlobalBestCost,'-r');
% title(['\fontsize{12}\bf Benchmark Function: F',num2str(Benchmark_Function_ID)]);
% xlabel('\fontsize{12}\bf Iteration');ylabel('\fontsize{12}\bf Fitness(Best-so-far)');
% legend('\fontsize{10}\bf PSOGSA','northeast');